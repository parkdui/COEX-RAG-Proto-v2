'use client';

import { useState, useEffect, useRef } from 'react';

interface Message {
  role: 'user' | 'assistant';
  content: string;
  timestamp?: Date;
  tokens?: {
    input: number;
    output: number;
    total: number;
  };
  hits?: Array<{
    id: string;
    meta: Record<string, unknown>;
    text: string;
    score: number;
  }>;
}

interface ChatBubbleProps {
  message: Message;
  isThinking?: boolean;
  onPlayTTS?: (text: string) => void;
  isPlayingTTS?: boolean;
}

function ChatBubble({ message, isThinking = false, onPlayTTS, isPlayingTTS = false }: ChatBubbleProps) {
  return (
    <div className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'} mb-4`}>
      <div className={`max-w-[86%] rounded-2xl px-4 py-3 ${
        message.role === 'user' 
          ? 'bg-gray-700 text-white' 
          : 'bg-gray-800 text-white border border-gray-600'
      }`}>
        <div className="whitespace-pre-wrap break-words">
          {message.content}
          {isThinking && (
            <span className="inline-block ml-2 w-4 h-4 border-2 border-blue-400 border-t-transparent rounded-full animate-spin"></span>
          )}
        </div>
        
        {/* TTS ë²„íŠ¼ - AI ì‘ë‹µì—ë§Œ í‘œì‹œ */}
        {message.role === 'assistant' && onPlayTTS && message.content && (
          <div className="mt-2 flex items-center gap-2">
            <button
              onClick={() => onPlayTTS(message.content)}
              disabled={isPlayingTTS}
              className={`px-3 py-1 rounded-lg text-xs font-medium transition-colors ${
                isPlayingTTS 
                  ? 'bg-gray-600 text-gray-400 cursor-not-allowed' 
                  : 'bg-blue-600 hover:bg-blue-700 text-white'
              }`}
              title={isPlayingTTS ? 'ìŒì„± ì¬ìƒ ì¤‘...' : 'ìŒì„±ìœ¼ë¡œ ë“£ê¸°'}
            >
              {isPlayingTTS ? (
                <span className="flex items-center gap-1">
                  <span className="inline-block w-3 h-3 border-2 border-white border-t-transparent rounded-full animate-spin"></span>
                  ì¬ìƒ ì¤‘...
                </span>
              ) : (
                <span className="flex items-center gap-1">
                  <svg className="w-3 h-3" fill="currentColor" viewBox="0 0 20 20">
                    <path fillRule="evenodd" d="M9.383 3.076A1 1 0 0110 4v12a1 1 0 01-1.617.794L4.617 13H2a1 1 0 01-1-1V8a1 1 0 011-1h2.617l3.766-3.794a1 1 0 011.617.794zM14.657 2.929a1 1 0 011.414 0A9.972 9.972 0 0119 10a9.972 9.972 0 01-2.929 7.071 1 1 0 01-1.414-1.414A7.971 7.971 0 0017 10c0-2.21-.894-4.208-2.343-5.657a1 1 0 010-1.414zm-2.829 2.828a1 1 0 011.415 0A5.983 5.983 0 0115 10a5.984 5.984 0 01-1.757 4.243 1 1 0 01-1.415-1.415A3.984 3.984 0 0013 10a3.983 3.983 0 00-1.172-2.828 1 1 0 010-1.415z" clipRule="evenodd" />
                  </svg>
                  ğŸ”Š ë“£ê¸°
                </span>
              )}
            </button>
          </div>
        )}
        
        {message.tokens && (
          <div className="mt-2 text-xs text-gray-400">
            ğŸ“Š í† í° ì‚¬ìš©ëŸ‰: ì…ë ¥ {message.tokens.input.toLocaleString()} / 
            ì¶œë ¥ {message.tokens.output.toLocaleString()} / 
            ì´ {message.tokens.total.toLocaleString()}
          </div>
        )}
        
        {message.hits && message.hits.length > 0 && (
          <details className="mt-2 text-xs text-gray-400">
            <summary className="cursor-pointer">ì°¸ì¡°í•œ ì´ë²¤íŠ¸ ({message.hits.length})</summary>
            <pre className="mt-2 p-2 bg-gray-900 rounded text-xs overflow-x-auto">
              {message.hits.map((hit, i) => 
                `[${i + 1}] ${hit.meta?.title || ''} | ${hit.meta?.date || ''} | ${hit.meta?.venue || ''}`
              ).join('\n')}
            </pre>
          </details>
        )}
      </div>
    </div>
  );
}

export default function Home() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputValue, setInputValue] = useState('');
  const [systemPrompt, setSystemPrompt] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [isGoButtonDisabled, setIsGoButtonDisabled] = useState(false);
  const [chatHistory, setChatHistory] = useState<Message[]>([]);

  const [isRecording, setIsRecording] = useState(false);
  const [isProcessingVoice, setIsProcessingVoice] = useState(false);
  const [isRequestingPermission, setIsRequestingPermission] = useState(false);
  const [isPlayingTTS, setIsPlayingTTS] = useState(false);
  const [autoPlayTTS, setAutoPlayTTS] = useState(false);
  const chatRef = useRef<HTMLDivElement>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  useEffect(() => {
    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    fetch('/LLM/system_prompt.txt')
      .then(response => {
        if (!response.ok) throw new Error('Network response was not ok');
        return response.text();
      })
      .then(text => setSystemPrompt(text))
      .catch(error => {
        console.error('system_prompt.txt íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤:', error);
        setSystemPrompt('system_prompt.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      });

    // ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ë° ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ í™•ì¸ (ì´ˆê¸° ë¡œë”© ì‹œ)
    const checkInitialSupport = async () => {
      // ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ì²´í¬
      if (!checkBrowserSupport()) {
        console.warn('ë¸Œë¼ìš°ì €ê°€ ìŒì„± ë…¹ìŒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
        return;
      }

      // ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ í™•ì¸
      if (navigator.permissions) {
        try {
          const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName });
          console.log('ì´ˆê¸° ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ:', permission.state);
          
          // ê¶Œí•œì´ ê±°ë¶€ëœ ê²½ìš° ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
          if (permission.state === 'denied') {
            console.warn('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
          }
        } catch (error) {
          console.log('ê¶Œí•œ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', error);
        }
      }
    };

    checkInitialSupport();
  }, []);

  useEffect(() => {
    if (chatRef.current) {
      chatRef.current.scrollTop = chatRef.current.scrollHeight;
    }
  }, [messages]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì˜¤ë””ì˜¤ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (audioRef.current) {
        audioRef.current.pause();
        URL.revokeObjectURL(audioRef.current.src);
      }
    };
  }, []);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    const text = inputValue.trim();
    if (!text) return;

    // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    const userMessage: Message = {
      role: 'user',
      content: text,
      timestamp: new Date()
    };
    setMessages(prev => [...prev, userMessage]);
    setChatHistory(prev => [...prev, userMessage]);

    setInputValue('');
    setIsLoading(true);

    try {
      // ë””ë²„ê¹… ë¡œê·¸: ì „ì†¡í•  íˆìŠ¤í† ë¦¬ í™•ì¸
      const historyToSend = chatHistory.slice(-10);
      console.log("=== FRONTEND DEBUG ===");
      console.log("Question:", text);
      console.log("History length:", historyToSend.length);
      console.log("History content:", JSON.stringify(historyToSend, null, 2));
      console.log("=====================");

      // ì„œë²„ë¡œ ì§ˆë¬¸ ì „ì†¡
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          question: text,
          systemPrompt: systemPrompt,
          history: historyToSend, // ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ì „ì†¡
        }),
      });

      const data = await response.json();
      
      if (data.error) {
        setMessages(prev => [...prev, {
          role: 'assistant',
          content: 'âš ï¸ ' + data.error,
          timestamp: new Date()
        }]);
      } else {
        const assistantMessage: Message = {
          role: 'assistant',
          content: data.answer || '(ì‘ë‹µ ì—†ìŒ)',
          timestamp: new Date(),
          tokens: data.tokens,
          hits: data.hits
        };
        setMessages(prev => [...prev, assistantMessage]);
        setChatHistory(prev => [...prev, assistantMessage]);
        
        // ìë™ TTS ì¬ìƒ
        handleAutoTTS(assistantMessage);
      }
    } catch (error) {
      console.error('API í˜¸ì¶œ ì‹¤íŒ¨:', error);
      setMessages(prev => [...prev, {
        role: 'assistant',
        content: 'âš ï¸ ì„œë²„ì™€ì˜ í†µì‹ ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
        timestamp: new Date()
      }]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleGoButton = async () => {
    setIsGoButtonDisabled(true);
    setIsLoading(true);

    try {
      // ë””ë²„ê¹… ë¡œê·¸: ì´ˆê¸° ëŒ€í™” ì‹œì‘
      console.log("=== GO BUTTON DEBUG ===");
      console.log("Initial question: ì•ˆë…•í•˜ì„¸ìš”! COEX ì´ë²¤íŠ¸ ì•ˆë‚´ AIì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?");
      console.log("History length: 0 (initial)");
      console.log("=====================");

      // CLOVA APIë¥¼ í†µí•´ ì‹¤ì œ ëŒ€í™” ì‹œì‘ ë©”ì‹œì§€ ìƒì„±
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          question: "ì•ˆë…•í•˜ì„¸ìš”! COEX ì´ë²¤íŠ¸ ì•ˆë‚´ AIì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
          systemPrompt: systemPrompt,
          history: [], // ì´ˆê¸° ëŒ€í™”ì´ë¯€ë¡œ ë¹ˆ íˆìŠ¤í† ë¦¬
        }),
      });

      const data = await response.json();
      
      if (data.error) {
        setMessages(prev => [...prev, {
          role: 'assistant',
          content: 'âš ï¸ ' + data.error,
          timestamp: new Date()
        }]);
      } else {
        const assistantMessage: Message = {
          role: 'assistant',
          content: data.answer || 'ì•ˆë…•í•˜ì„¸ìš”! COEX ì´ë²¤íŠ¸ ì•ˆë‚´ AIì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?',
          timestamp: new Date(),
          tokens: data.tokens,
          hits: data.hits
        };
        setMessages(prev => [...prev, assistantMessage]);
        setChatHistory(prev => [...prev, assistantMessage]);
        
        // ìë™ TTS ì¬ìƒ
        handleAutoTTS(assistantMessage);
      }
    } catch (error) {
      console.error('ëŒ€í™” ì‹œì‘ ì‹¤íŒ¨:', error);
      setMessages(prev => [...prev, {
        role: 'assistant',
        content: 'âš ï¸ ì„œë²„ì™€ì˜ í†µì‹ ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
        timestamp: new Date()
      }]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleKeyDown = (e: React.KeyboardEvent) => {
    if ((e.nativeEvent as any).isComposing) return;
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSubmit(e);
    }
  };

  // WAV í˜•ì‹ìœ¼ë¡œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
  const createWavBlob = (audioBuffer: Float32Array, sampleRate: number): Blob => {
    const length = audioBuffer.length;
    const buffer = new ArrayBuffer(44 + length * 2);
    const view = new DataView(buffer);
    
    // WAV í—¤ë” ì‘ì„±
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + length * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, 1, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, length * 2, true);
    
    // ì˜¤ë””ì˜¤ ë°ì´í„° ì‘ì„±
    let offset = 44;
    for (let i = 0; i < length; i++) {
      const sample = Math.max(-1, Math.min(1, audioBuffer[i]));
      view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
      offset += 2;
    }
    
    return new Blob([buffer], { type: 'audio/wav' });
  };

  // ìŒì„± ë…¹ìŒ ì‹œì‘ (WAV í˜•ì‹ìœ¼ë¡œ)
  const startRecording = async () => {
    try {
      // ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ë¨¼ì € ì²´í¬
      if (!checkBrowserSupport()) {
        return;
      }

      // ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € í˜¸í™˜ì„±ì„ ìœ„í•œ ì˜¤ë””ì˜¤ ì„¤ì •
      const audioConstraints = {
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          // ëª¨ë°”ì¼ì—ì„œ ë” ì•ˆì •ì ì¸ ì„¤ì •
          latency: 0.01
        }
      };

      const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
      
      // ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € í˜¸í™˜ì„±ì„ ìœ„í•œ AudioContext ìƒì„±
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
      const audioContext = new AudioContextClass({
        sampleRate: 16000,
        latencyHint: 'interactive'
      });
      
      // ëª¨ë°”ì¼ì—ì„œ AudioContextê°€ suspended ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ resume
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
      }
      
      const source = audioContext.createMediaStreamSource(stream);
      
      // ëª¨ë°”ì¼ì—ì„œ ë” ì•ˆì •ì ì¸ ë²„í¼ í¬ê¸° ì‚¬ìš©
      const bufferSize = 4096;
      const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
      
      const audioData: Float32Array[] = [];
      
      processor.onaudioprocess = (event) => {
        const inputData = event.inputBuffer.getChannelData(0);
        audioData.push(new Float32Array(inputData));
      };
      
      source.connect(processor);
      processor.connect(audioContext.destination);
      
      // ë…¹ìŒ ì¤‘ì§€ ì‹œ WAV íŒŒì¼ ìƒì„±
      const stopRecording = () => {
        processor.disconnect();
        source.disconnect();
        audioContext.close();
        stream.getTracks().forEach(track => track.stop());
        
        // ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ í•©ì¹˜ê¸°
        const totalLength = audioData.reduce((sum, chunk) => sum + chunk.length, 0);
        const combinedAudio = new Float32Array(totalLength);
        let offset = 0;
        
        for (const chunk of audioData) {
          combinedAudio.set(chunk, offset);
          offset += chunk.length;
        }
        
        // WAV íŒŒì¼ ìƒì„±
        const wavBlob = createWavBlob(combinedAudio, 16000);
        processAudio(wavBlob, 'audio/wav');
        setIsRecording(false);
      };
      
      // ì „ì—­ stopRecording í•¨ìˆ˜ ì„¤ì •
      (window as any).stopRecording = stopRecording;
      setIsRecording(true);
      
    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', error);
      
      // ëª¨ë°”ì¼ì—ì„œ ë” êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ì œê³µ
      let errorMessage = 'ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.';
      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          errorMessage = 'ë§ˆì´í¬ ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.';
        } else if (error.name === 'NotSupportedError') {
          errorMessage = 'ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ë…¹ìŒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.';
        } else if (error.name === 'NotReadableError') {
          errorMessage = 'ë§ˆì´í¬ê°€ ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì•±ì„ ì¢…ë£Œí•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
        } else if (error.name === 'OverconstrainedError') {
          errorMessage = 'ë§ˆì´í¬ ì„¤ì •ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.';
        }
      }
      
      alert(errorMessage);
    }
  };

  // ìŒì„± ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    if (isRecording && (window as any).stopRecording) {
      (window as any).stopRecording();
    }
  };

  // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë° STT
  const processAudio = async (audioBlob: Blob, mimeType?: string) => {
    setIsProcessingVoice(true);
    
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.wav');

      const response = await fetch('/api/stt', {
        method: 'POST',
        body: formData,
      });

      const result = await response.json();

      if (result.success && result.text) {
        setInputValue(result.text);
        // ìë™ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡
        const userMessage: Message = {
          role: 'user',
          content: result.text,
          timestamp: new Date()
        };
        setMessages(prev => [...prev, userMessage]);
        setChatHistory(prev => [...prev, userMessage]);

        // AI ì‘ë‹µ ìš”ì²­
        setIsLoading(true);
        try {
          const historyToSend = chatHistory.slice(-10);
          const chatResponse = await fetch('/api/chat', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              question: result.text,
              systemPrompt: systemPrompt,
              history: historyToSend,
            }),
          });

          const chatData = await chatResponse.json();
          
          if (chatData.error) {
            setMessages(prev => [...prev, {
              role: 'assistant',
              content: 'âš ï¸ ' + chatData.error,
              timestamp: new Date()
            }]);
          } else {
            const assistantMessage: Message = {
              role: 'assistant',
              content: chatData.answer || '(ì‘ë‹µ ì—†ìŒ)',
              timestamp: new Date(),
              tokens: chatData.tokens,
              hits: chatData.hits
            };
            setMessages(prev => [...prev, assistantMessage]);
            setChatHistory(prev => [...prev, assistantMessage]);
            
            // ìë™ TTS ì¬ìƒ
            handleAutoTTS(assistantMessage);
          }
        } catch (error) {
          console.error('AI ì‘ë‹µ ìš”ì²­ ì‹¤íŒ¨:', error);
          setMessages(prev => [...prev, {
            role: 'assistant',
            content: 'âš ï¸ ì„œë²„ì™€ì˜ í†µì‹ ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            timestamp: new Date()
          }]);
        } finally {
          setIsLoading(false);
        }
      } else {
        // STT007 ì˜¤ë¥˜ (ìŒì„± ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ìŒ) íŠ¹ë³„ ì²˜ë¦¬
        if (result.details && result.details.includes('STT007')) {
          alert('ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 1ì´ˆ ì´ìƒ ë§ì”€í•´ì£¼ì„¸ìš”.');
        } else {
          alert('ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
        }
      }
    } catch (error) {
      console.error('STT ì²˜ë¦¬ ì˜¤ë¥˜:', error);
      alert('ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsProcessingVoice(false);
    }
  };

  // ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ì²´í¬
  const checkBrowserSupport = () => {
    // HTTPS ì²´í¬
    if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
      alert('ìŒì„± ë…¹ìŒ ê¸°ëŠ¥ì€ HTTPS í™˜ê²½ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ HTTP í™˜ê²½ì…ë‹ˆë‹¤.');
      return false;
    }

    // getUserMedia ì§€ì› ì²´í¬
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ë…¹ìŒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìµœì‹  ë¸Œë¼ìš°ì €ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
      return false;
    }

    // Web Audio API ì§€ì› ì²´í¬
    if (!window.AudioContext && !(window as any).webkitAudioContext) {
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” Web Audio APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìµœì‹  ë¸Œë¼ìš°ì €ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
      return false;
    }

    return true;
  };

  // ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ ë° ìš”ì²­
  const checkMicrophonePermission = async () => {
    setIsRequestingPermission(true);
    
    try {
      // ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ë¨¼ì € ì²´í¬
      if (!checkBrowserSupport()) {
        return false;
      }

      // ê¶Œí•œ ìƒíƒœ í™•ì¸
      if (navigator.permissions) {
        const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        console.log('ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ:', permission.state);
        
        if (permission.state === 'denied') {
          alert('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
          return false;
        }
      }
      
      // ì‹¤ì œ ë§ˆì´í¬ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: { 
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      
      // ì¦‰ì‹œ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ (ê¶Œí•œ í™•ì¸ë§Œì„ ìœ„í•´)
      stream.getTracks().forEach(track => track.stop());
      
      return true;
    } catch (error) {
      console.error('ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ ì˜¤ë¥˜:', error);
      
      // ëª¨ë°”ì¼ì—ì„œ ë” êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ì œê³µ
      let errorMessage = 'ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.';
      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          errorMessage = 'ë§ˆì´í¬ ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.';
        } else if (error.name === 'NotSupportedError') {
          errorMessage = 'ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ë…¹ìŒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.';
        } else if (error.name === 'NotReadableError') {
          errorMessage = 'ë§ˆì´í¬ê°€ ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì•±ì„ ì¢…ë£Œí•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
        } else if (error.name === 'OverconstrainedError') {
          errorMessage = 'ë§ˆì´í¬ ì„¤ì •ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.';
        }
      }
      
      alert(errorMessage);
      return false;
    } finally {
      setIsRequestingPermission(false);
    }
  };

  // ë§ˆì´í¬ ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬ (ëª¨ë°”ì¼ í„°ì¹˜ ìµœì í™”)
  const handleMicClick = async (e: React.MouseEvent | React.TouchEvent) => {
    e.preventDefault();
    e.stopPropagation();
    
    if (isRecording) {
      stopRecording();
    } else {
      // ê¶Œí•œ í™•ì¸ í›„ ë…¹ìŒ ì‹œì‘
      const hasPermission = await checkMicrophonePermission();
      if (hasPermission) {
        startRecording();
      } else {
        alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      }
    }
  };

  // í„°ì¹˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ (ëª¨ë°”ì¼ì—ì„œ ë” ë‚˜ì€ ë°˜ì‘ì„±)
  const handleTouchStart = async (e: React.TouchEvent) => {
    e.preventDefault();
    if (!isRecording) {
      const hasPermission = await checkMicrophonePermission();
      if (hasPermission) {
        startRecording();
      } else {
        alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      }
    }
  };

  const handleTouchEnd = (e: React.TouchEvent) => {
    e.preventDefault();
    if (isRecording) {
      stopRecording();
    }
  };

  // TTS ê¸°ëŠ¥
  const playTTS = async (text: string) => {
    if (isPlayingTTS) {
      // ì´ë¯¸ ì¬ìƒ ì¤‘ì´ë©´ ì¤‘ì§€
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.currentTime = 0;
      }
      setIsPlayingTTS(false);
      return;
    }

    try {
      setIsPlayingTTS(true);

      // TTS API í˜¸ì¶œ
      const response = await fetch('/api/tts', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          text: text,
          speaker: 'nara',
          speed: '0',
          pitch: '0',
          volume: '0',
          format: 'mp3'
        }),
      });

      if (!response.ok) {
        throw new Error(`TTS API failed: ${response.status}`);
      }

      // ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
      const audioBlob = await response.blob();
      const audioUrl = URL.createObjectURL(audioBlob);

      // ê¸°ì¡´ ì˜¤ë””ì˜¤ ì •ë¦¬
      if (audioRef.current) {
        audioRef.current.pause();
        URL.revokeObjectURL(audioRef.current.src);
      }

      // ìƒˆ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
      const audio = new Audio(audioUrl);
      audioRef.current = audio;

      // ì˜¤ë””ì˜¤ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
      audio.onended = () => {
        setIsPlayingTTS(false);
        URL.revokeObjectURL(audioUrl);
      };

      audio.onerror = () => {
        setIsPlayingTTS(false);
        URL.revokeObjectURL(audioUrl);
        console.error('TTS audio playback failed');
      };

      // ì˜¤ë””ì˜¤ ì¬ìƒ
      await audio.play();

    } catch (error) {
      console.error('TTS error:', error);
      setIsPlayingTTS(false);
      alert('ìŒì„± ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    }
  };

  // ìë™ TTS ì¬ìƒ (AI ì‘ë‹µì— ëŒ€í•´)
  const handleAutoTTS = (message: Message) => {
    if (autoPlayTTS && message.role === 'assistant' && message.content) {
      // ì•½ê°„ì˜ ì§€ì—° í›„ ì¬ìƒ (UI ì—…ë°ì´íŠ¸ ì™„ë£Œ í›„)
      setTimeout(() => {
        playTTS(message.content);
      }, 500);
    }
  };

  return (
    <div className="min-h-screen bg-gray-900 text-white flex flex-col safe-area-inset">
      {/* Header */}
      <header className="sticky top-0 z-10 bg-gray-800 bg-opacity-95 backdrop-blur-sm border-b border-gray-700 px-4 py-3">
        <div className="max-w-4xl mx-auto flex justify-between items-center">
          <h1 className="text-lg sm:text-xl font-bold">COEX ì´ë²¤íŠ¸ ì•ˆë‚´</h1>
          <div className="flex items-center gap-3">
            {/* ìë™ TTS í† ê¸€ ë²„íŠ¼ */}
            <button
              onClick={() => setAutoPlayTTS(!autoPlayTTS)}
              className={`px-3 py-1 rounded-lg text-xs font-medium transition-colors ${
                autoPlayTTS 
                  ? 'bg-green-600 hover:bg-green-700 text-white' 
                  : 'bg-gray-600 hover:bg-gray-700 text-gray-300'
              }`}
              title={autoPlayTTS ? 'ìë™ ìŒì„± ì¬ìƒ ì¼œì§' : 'ìë™ ìŒì„± ì¬ìƒ ë”'}
            >
              {autoPlayTTS ? 'ğŸ”Š ìë™ì¬ìƒ' : 'ğŸ”‡ ìˆ˜ë™ì¬ìƒ'}
            </button>
            <div className="text-xs sm:text-sm text-green-400">
              ì˜¨ë¼ì¸
            </div>
          </div>
        </div>
      </header>

      <div className="flex-1 flex flex-col lg:flex-row max-w-4xl mx-auto w-full min-h-0">
        {/* Sidebar - ëª¨ë°”ì¼ì—ì„œëŠ” ì ‘ì„ ìˆ˜ ìˆê²Œ */}
        <aside className="hidden lg:block w-80 bg-gray-800 p-4 border-r border-gray-700">
          <h3 className="text-lg font-semibold mb-3">System Prompt</h3>
          <textarea
            value={systemPrompt}
            onChange={(e) => setSystemPrompt(e.target.value)}
            disabled={isGoButtonDisabled}
            rows={10}
            className="w-full p-3 bg-gray-700 border border-gray-600 rounded-lg text-sm resize-none focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:opacity-50"
            placeholder="System Promptë¥¼ ì…ë ¥í•˜ì„¸ìš”"
          />
          <button
            onClick={handleGoButton}
            disabled={isGoButtonDisabled}
            className="w-full mt-3 px-4 py-2 bg-blue-600 hover:bg-blue-700 disabled:bg-gray-600 disabled:cursor-not-allowed rounded-lg font-semibold transition-colors"
          >
            {isGoButtonDisabled ? 'ëŒ€í™” ì¤‘...' : 'go'}
          </button>
        </aside>

        {/* Main Chat Area */}
        <main className="flex-1 flex flex-col min-h-0">
          <div ref={chatRef} className="flex-1 overflow-y-auto p-2 sm:p-4 space-y-3 sm:space-y-4 overscroll-contain">
            {messages.map((message, index) => (
              <ChatBubble 
                key={index} 
                message={message} 
                onPlayTTS={playTTS}
                isPlayingTTS={isPlayingTTS}
              />
            ))}
            {isLoading && (
              <ChatBubble 
                message={{ role: 'assistant', content: 'ìƒê° ì¤‘â€¦' }} 
                isThinking={true}
              />
            )}
          </div>

          {/* Input Form - ëª¨ë°”ì¼ ìµœì í™” */}
          <form onSubmit={handleSubmit} className="p-2 sm:p-4 border-t border-gray-700 bg-gray-900">
            <div className="flex gap-1 sm:gap-2">
              <input
                type="text"
                value={inputValue}
                onChange={(e) => setInputValue(e.target.value)}
                onKeyDown={handleKeyDown}
                placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
                className="flex-1 px-3 sm:px-4 py-2 sm:py-3 bg-gray-700 border border-gray-600 rounded-lg sm:rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 text-sm sm:text-base"
                disabled={isLoading || isProcessingVoice}
                autoComplete="off"
                autoCorrect="off"
                autoCapitalize="off"
                spellCheck="false"
              />
              <button
                type="button"
                onClick={handleMicClick}
                onTouchStart={handleTouchStart}
                onTouchEnd={handleTouchEnd}
                disabled={isLoading || isProcessingVoice || isRequestingPermission}
                className={`px-3 sm:px-4 py-2 sm:py-3 rounded-lg sm:rounded-xl font-semibold transition-colors touch-manipulation select-none ${
                  isRecording 
                    ? 'bg-red-600 hover:bg-red-700 active:bg-red-800 text-white' 
                    : 'bg-gray-600 hover:bg-gray-700 active:bg-gray-800 text-white disabled:bg-gray-500 disabled:cursor-not-allowed'
                }`}
                title={isRecording ? 'ë…¹ìŒ ì¤‘ì§€' : isRequestingPermission ? 'ê¶Œí•œ ìš”ì²­ ì¤‘...' : 'ìŒì„± ì…ë ¥'}
                style={{ WebkitTapHighlightColor: 'transparent' }}
              >
                {isProcessingVoice ? (
                  <span className="inline-block w-4 h-4 sm:w-5 sm:h-5 border-2 border-white border-t-transparent rounded-full animate-spin"></span>
                ) : isRequestingPermission ? (
                  <span className="inline-block w-4 h-4 sm:w-5 sm:h-5 border-2 border-white border-t-transparent rounded-full animate-spin"></span>
                ) : isRecording ? (
                  <svg className="w-4 h-4 sm:w-5 sm:h-5" fill="currentColor" viewBox="0 0 20 20">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 012 0v4a1 1 0 11-2 0V7zm4 0a1 1 0 012 0v4a1 1 0 11-2 0V7z" clipRule="evenodd" />
                  </svg>
                ) : (
                  <svg className="w-4 h-4 sm:w-5 sm:h-5" fill="currentColor" viewBox="0 0 20 20">
                    <path fillRule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clipRule="evenodd" />
                  </svg>
                )}
              </button>
              <button
                type="submit"
                disabled={isLoading || !inputValue.trim() || isProcessingVoice}
                className="px-4 sm:px-6 py-2 sm:py-3 bg-blue-600 hover:bg-blue-700 active:bg-blue-800 disabled:bg-gray-600 disabled:cursor-not-allowed rounded-lg sm:rounded-xl font-semibold transition-colors text-sm sm:text-base touch-manipulation select-none"
                style={{ WebkitTapHighlightColor: 'transparent' }}
              >
                ë³´ë‚´ê¸°
              </button>
            </div>
            {isRequestingPermission && (
              <div className="mt-2 text-center text-xs sm:text-sm text-yellow-400 animate-pulse">
                ğŸ” ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘... ë¸Œë¼ìš°ì €ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”
              </div>
            )}
            {isRecording && (
              <div className="mt-2 text-center text-xs sm:text-sm text-red-400 animate-pulse">
                ğŸ¤ ë…¹ìŒ ì¤‘... ìµœì†Œ 1ì´ˆ ì´ìƒ ë§ì”€í•´ì£¼ì„¸ìš”
              </div>
            )}
            {isProcessingVoice && (
              <div className="mt-2 text-center text-xs sm:text-sm text-blue-400">
                ğŸ”„ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...
              </div>
            )}
          </form>
        </main>
      </div>
    </div>
  );
}